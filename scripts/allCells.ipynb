{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc0534b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import detectron2\n",
    "\n",
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, json, cv2, random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import image processing\n",
    "from skimage import measure\n",
    "from skimage import img_as_float\n",
    "from scipy.spatial import ConvexHull\n",
    "\n",
    "# from google.colab.patches import cv2_imshow\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.structures import BoxMode\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0eb017b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('../data')\n",
    "\n",
    "dataDir = '../data/allCells'\n",
    "\n",
    "jsonAnnotations = os.path.join(dataDir, 'annotations', 'train.json')\n",
    "imgDir = os.path.join(dataDir, 'images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "287149eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data.datasets import register_coco_instances\n",
    "register_coco_instances(\"allCells_train\", {}, jsonAnnotations, imgDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa14ed0d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DatasetCatalog' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m datasetDicts \u001b[38;5;241m=\u001b[39m \u001b[43mDatasetCatalog\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mallCells_train\u001b[39m\u001b[38;5;124m'\u001b[39m]()\n\u001b[1;32m      2\u001b[0m random\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m1234\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m random\u001b[38;5;241m.\u001b[39msample(datasetDicts, \u001b[38;5;241m5\u001b[39m):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DatasetCatalog' is not defined"
     ]
    }
   ],
   "source": [
    "datasetDicts = DatasetCatalog['allCells_train']()\n",
    "random.seed(1234)\n",
    "for d in random.sample(datasetDicts, 5):\n",
    "    print(d[\"file_name\"])\n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    visualizer = Visualizer(img[:, :, ::-1], metadata=MetadataCatalog.get('allCells_train'), scale=0.5)\n",
    "    out = visualizer.draw_dataset_dict(d)\n",
    "    plt.imshow(out.get_image()[:, :, ::-1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8269479",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "\n",
    "cfg = get_cfg()\n",
    "if not torch.cuda.is_available():\n",
    "    print('CUDA not available, resorting to CPU')\n",
    "    cfg.MODEL.DEVICE='cpu'\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"allCells_train\",)\n",
    "cfg.DATASETS.TEST = ()\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2  # This is the real \"batch size\" commonly known to deep learning people\n",
    "cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 10000    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n",
    "cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512   # The \"RoIHead batch size\". 128 is faster, and good enough for this toy dataset (default: 512)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (cell). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
    "# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n",
    "cfg.OUTPUT_DIR = '../output/segmentCells'\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
